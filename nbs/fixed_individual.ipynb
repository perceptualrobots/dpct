{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71858cc0",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: individual.html\n",
    "title: DHPCTIndividual\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea870ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd3b118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a0652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbdev import *\n",
    "# default_exp individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12cce171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Multiply\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebdd2f",
   "metadata": {},
   "source": [
    "# DHPCTIndividual\n",
    "\n",
    "> Class for implementing Deep Perceptual Control Theory individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb2a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DHPCTIndividual:\n",
    "    \"\"\"DHPCTIndividual encapsulates an environment and a keras model representing a PCT hierarchy.\"\"\"\n",
    "    \n",
    "    def __init__(self, env_name, env_props=None, levels=None, activation_funcs=None, weight_types=None):\n",
    "        \"\"\"\n",
    "        Initialize a new individual with environment and hierarchy specifications.\n",
    "        \n",
    "        Parameters:\n",
    "        - env_name: Name of the OpenAI Gym environment to use (e.g. 'CartPole-v1')\n",
    "        - env_props: Dictionary of environment properties\n",
    "        - levels: List of dictionaries specifying each level in the hierarchy\n",
    "        - activation_funcs: List of activation functions for each level\n",
    "        - weight_types: List of weight initialization methods for each level\n",
    "        \"\"\"\n",
    "        self.env_name = env_name\n",
    "        self.env_props = env_props or {}\n",
    "        self.levels = levels or []\n",
    "        self.activation_funcs = activation_funcs or []\n",
    "        self.weight_types = weight_types or []\n",
    "        self.env = None\n",
    "        self.model = None\n",
    "        \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        \"\"\"\n",
    "        Create an individual from a configuration dictionary.\n",
    "        \n",
    "        Parameters:\n",
    "        - config: Dictionary containing individual configuration\n",
    "        \n",
    "        Returns:\n",
    "        - DHPCTIndividual instance\n",
    "        \"\"\"\n",
    "        return cls(\n",
    "            env_name=config['env_name'],\n",
    "            env_props=config.get('env_props', {}),\n",
    "            levels=config.get('levels', []),\n",
    "            activation_funcs=config.get('activation_funcs', []),\n",
    "            weight_types=config.get('weight_types', [])\n",
    "        )\n",
    "    \n",
    "    def compile(self):\n",
    "        \"\"\"\n",
    "        Build the environment and Keras model based on specifications.\n",
    "        \"\"\"\n",
    "        # Initialize the environment\n",
    "        self.env = gym.make(self.env_name, **self.env_props)\n",
    "        \n",
    "        # Get environment dimensions\n",
    "        state_dim = self.env.observation_space.shape[0]\n",
    "        action_dim = self.env.action_space.shape[0] if hasattr(self.env.action_space, 'shape') else self.env.action_space.n\n",
    "        \n",
    "        # Build Keras model\n",
    "        inputs = Input(shape=(state_dim,), name='env_input')\n",
    "        x = inputs\n",
    "        \n",
    "        # Build hierarchy levels\n",
    "        for i, level_spec in enumerate(self.levels):\n",
    "            # Reference signal (desired perceptual signal)\n",
    "            if i == 0:\n",
    "                # First level uses external input as reference\n",
    "                reference = x\n",
    "            else:\n",
    "                # Higher levels use output from level above as reference\n",
    "                reference = Dense(level_spec['units'],\n",
    "                                name=f'reference_{i}',\n",
    "                                activation=self.activation_funcs[i] if i < len(self.activation_funcs) else 'linear')(x)\n",
    "            \n",
    "            # Perception (current perceptual signal)\n",
    "            perception = Dense(level_spec['units'],\n",
    "                             name=f'perception_{i}',\n",
    "                             activation=self.activation_funcs[i] if i < len(self.activation_funcs) else 'linear')(x)\n",
    "            \n",
    "            # Error (difference between reference and perception)\n",
    "            error = Lambda(lambda inputs: inputs[0] - inputs[1], name=f'error_{i}')([reference, perception])\n",
    "            \n",
    "            # Output (action to reduce error)\n",
    "            x = Dense(level_spec['units'],\n",
    "                    name=f'output_{i}',\n",
    "                    activation=self.activation_funcs[i] if i < len(self.activation_funcs) else 'linear')(error)\n",
    "        \n",
    "        # Final layer (outputs action to environment)\n",
    "        outputs = Dense(action_dim, name='action', activation='tanh')(x)\n",
    "        \n",
    "        # Create model\n",
    "        self.model = Model(inputs=inputs, outputs=outputs)\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def config(self):\n",
    "        \"\"\"\n",
    "        Return a dictionary of individual's properties.\n",
    "        \n",
    "        Returns:\n",
    "        - Dictionary containing configuration\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'env_name': self.env_name,\n",
    "            'env_props': self.env_props,\n",
    "            'levels': self.levels,\n",
    "            'activation_funcs': self.activation_funcs,\n",
    "            'weight_types': self.weight_types\n",
    "        }\n",
    "    \n",
    "    def save_config(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the configuration to a JSON file.\n",
    "        \n",
    "        Parameters:\n",
    "        - filepath: Path to save the configuration file\n",
    "        \n",
    "        Returns:\n",
    "        - True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(self.config(), f, indent=2)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving configuration: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def run(self, steps=1000, train=False, early_termination=True):\n",
    "        \"\"\"\n",
    "        Run the individual in its environment for a number of steps.\n",
    "        \n",
    "        Parameters:\n",
    "        - steps: Maximum number of steps to run\n",
    "        - train: Whether to update weights during run\n",
    "        - early_termination: Whether to stop if environment signals done\n",
    "        \n",
    "        Returns:\n",
    "        - Total reward accumulated during the run\n",
    "        \"\"\"\n",
    "        if self.env is None:\n",
    "            self.compile()\n",
    "        \n",
    "        state, _ = self.env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            # Get action from model\n",
    "            action = self.model.predict(state.reshape(1, -1))[0]\n",
    "            \n",
    "            # Take action in environment\n",
    "            next_state, reward, done, truncated, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Update model if training enabled\n",
    "            if train:\n",
    "                # Implement online learning logic here\n",
    "                pass\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            if (done or truncated) and early_termination:\n",
    "                break\n",
    "        \n",
    "        return total_reward\n",
    "    \n",
    "    def mate(self, other):\n",
    "        \"\"\"\n",
    "        Create two new individuals by crossing this one with another.\n",
    "        \n",
    "        Parameters:\n",
    "        - other: Another DHPCTIndividual to mate with\n",
    "        \n",
    "        Returns:\n",
    "        - Two new DHPCTIndividual instances\n",
    "        \"\"\"\n",
    "        # Implement crossover logic here\n",
    "        return None, None\n",
    "    \n",
    "    def mutate(self, struct_prob=0.1, weight_prob=0.1):\n",
    "        \"\"\"\n",
    "        Mutate this individual's structure and/or weights.\n",
    "        \n",
    "        Parameters:\n",
    "        - struct_prob: Probability of structure mutation\n",
    "        - weight_prob: Probability of weight mutation\n",
    "        \n",
    "        Returns:\n",
    "        - Self (for method chaining)\n",
    "        \"\"\"\n",
    "        # Implement mutation logic here\n",
    "        return self\n",
    "    \n",
    "    def evaluate(self, nevals=1):\n",
    "        \"\"\"\n",
    "        Evaluate this individual's fitness by running it multiple times.\n",
    "        \n",
    "        Parameters:\n",
    "        - nevals: Number of evaluation runs\n",
    "        \n",
    "        Returns:\n",
    "        - Average fitness score\n",
    "        \"\"\"\n",
    "        scores = [self.run() for _ in range(nevals)]\n",
    "        return sum(scores) / len(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
