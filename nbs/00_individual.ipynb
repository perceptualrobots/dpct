{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d206a47",
   "metadata": {},
   "source": [
    "# DHPCTIndividual\n",
    "\n",
    "> Hierarchical Perceptual Control Theory individual with Keras model compilation and environment execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b0171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import gymnasium as gym\n",
    "import json\n",
    "import pickle\n",
    "from typing import Optional, Union, Callable, Dict, List, Set, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ElementWiseMultiplyLayer(layers.Layer):\n",
    "    \"\"\"Custom layer for element-wise multiplication with learnable weights.\"\"\"\n",
    "    \n",
    "    def __init__(self, units, weight_initializer, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.weight_initializer = weight_initializer\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.output_weights = self.add_weight(\n",
    "            name='output_weights',\n",
    "            shape=(self.units,),\n",
    "            initializer=self.weight_initializer,\n",
    "            trainable=True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs * self.output_weights\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'units': self.units,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d18b5e",
   "metadata": {},
   "source": [
    "## DHPCTIndividual Class\n",
    "\n",
    "The `DHPCTIndividual` class represents a single hierarchical Perceptual Control Theory (PCT) system. It manages:\n",
    "\n",
    "- **Hierarchy structure**: Levels with configurable units per level\n",
    "- **Keras model**: Functional API model with perception, reference, comparator, and output layers\n",
    "- **Environment interaction**: Gymnasium environment execution with fitness evaluation\n",
    "- **Configuration management**: Save/load complete hierarchy specifications\n",
    "- **Evolutionary operators**: Mutation, crossover for evolutionary algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DHPCTIndividual:\n",
    "    \"\"\"\n",
    "    Represents a hierarchical Perceptual Control Theory system with Keras model.\n",
    "    \n",
    "    This class manages the creation, compilation, execution, and evolution of\n",
    "    hierarchical control systems following PCT principles.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env_name: str,\n",
    "        levels: List[int],\n",
    "        activation_funcs: Union[str, List[str]] = \"linear\",\n",
    "        weight_types: Union[str, List[str]] = \"float\",\n",
    "        fixed_weights: Optional[Set[str]] = None,\n",
    "        fixed_levels: Optional[Set[int]] = None,\n",
    "        obs_connection_level: int = 0,\n",
    "        random_seed: Optional[int] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize a DHPCTIndividual.\n",
    "        \n",
    "        Args:\n",
    "            env_name: Gymnasium environment identifier (e.g., 'CartPole-v1')\n",
    "            levels: Number of units per level, bottom to top (e.g., [4, 3, 2])\n",
    "            activation_funcs: Activation function(s) - single string or list per level\n",
    "            weight_types: Weight type(s) - 'float', 'boolean', or 'ternary'\n",
    "            fixed_weights: Set of layer names that should not mutate\n",
    "            fixed_levels: Set of level indices that should not mutate\n",
    "            obs_connection_level: Which level receives environment observations (default: 0)\n",
    "            random_seed: Seed for reproducible weight initialization\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If levels is empty or configuration is invalid\n",
    "            EnvironmentError: If environment cannot be created\n",
    "        \"\"\"\n",
    "        # Validation\n",
    "        if not levels or len(levels) == 0:\n",
    "            raise ValueError(\"levels must have at least one element\")\n",
    "        if any(l < 1 for l in levels):\n",
    "            raise ValueError(\"All level sizes must be >= 1\")\n",
    "        \n",
    "        # Store parameters\n",
    "        self.env_name = env_name\n",
    "        self.levels = levels\n",
    "        self.obs_connection_level = obs_connection_level\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        # Handle activation functions\n",
    "        if isinstance(activation_funcs, str):\n",
    "            self.activation_funcs = [activation_funcs] * len(levels)\n",
    "        else:\n",
    "            if len(activation_funcs) != len(levels):\n",
    "                raise ValueError(f\"activation_funcs length ({len(activation_funcs)}) must match levels length ({len(levels)})\")\n",
    "            self.activation_funcs = activation_funcs\n",
    "        \n",
    "        # Handle weight types\n",
    "        if isinstance(weight_types, str):\n",
    "            self.weight_types = [weight_types] * len(levels)\n",
    "        else:\n",
    "            if len(weight_types) != len(levels):\n",
    "                raise ValueError(f\"weight_types length ({len(weight_types)}) must match levels length ({len(levels)})\")\n",
    "            self.weight_types = weight_types\n",
    "        \n",
    "        # Validate obs_connection_level\n",
    "        if obs_connection_level >= len(levels):\n",
    "            raise ValueError(f\"obs_connection_level ({obs_connection_level}) must be < len(levels) ({len(levels)})\")\n",
    "        \n",
    "        # Initialize state\n",
    "        self.fixed_weights = fixed_weights if fixed_weights is not None else set()\n",
    "        self.fixed_levels = fixed_levels if fixed_levels is not None else set()\n",
    "        self.model = None\n",
    "        self.weights = {}\n",
    "        self.fitness = None\n",
    "        self.history = None\n",
    "        \n",
    "        # Validate environment\n",
    "        try:\n",
    "            test_env = gym.make(env_name)\n",
    "            self.env_properties = {\n",
    "                'observation_space': str(test_env.observation_space),\n",
    "                'action_space': str(test_env.action_space),\n",
    "                'observation_shape': test_env.observation_space.shape,\n",
    "                'action_shape': test_env.action_space.shape if hasattr(test_env.action_space, 'shape') else (test_env.action_space.n,)\n",
    "            }\n",
    "            test_env.close()\n",
    "        except Exception as e:\n",
    "            raise EnvironmentError(f\"Failed to create environment '{env_name}': {e}\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        compiled_status = \"compiled\" if self.model is not None else \"uncompiled\"\n",
    "        fitness_str = f\", fitness={self.fitness:.2f}\" if self.fitness is not None else \"\"\n",
    "        return f\"DHPCTIndividual(env='{self.env_name}', levels={self.levels}, {compiled_status}{fitness_str})\"\n",
    "    \n",
    "    def compile(self):\n",
    "        \"\"\"\n",
    "        Build Keras Functional API model from hierarchy specification.\n",
    "        \n",
    "        Creates perception, reference, comparator, and output layers for each level\n",
    "        following PCT principles. Initializes weights according to weight_types.\n",
    "        \n",
    "        Raises:\n",
    "            RuntimeError: If already compiled\n",
    "            ValueError: If hierarchy specification is invalid\n",
    "        \"\"\"\n",
    "        if self.model is not None:\n",
    "            raise RuntimeError(\"Individual is already compiled\")\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "            tf.random.set_seed(self.random_seed)\n",
    "        \n",
    "        # Get environment dimensions\n",
    "        obs_shape = self.env_properties['observation_shape']\n",
    "        action_shape = self.env_properties['action_shape']\n",
    "        obs_dim = obs_shape[0] if len(obs_shape) > 0 else 1\n",
    "        action_dim = action_shape[0] if len(action_shape) > 0 else 1\n",
    "        \n",
    "        # Create input layers\n",
    "        observations = layers.Input(shape=(obs_dim,), name='Observations')\n",
    "        \n",
    "        # Calculate reference input dimension (sum of all level outputs except lowest)\n",
    "        ref_dim = sum(self.levels[1:]) if len(self.levels) > 1 else self.levels[0]\n",
    "        references_input = layers.Input(shape=(ref_dim,), name='ReferencesInput')\n",
    "        \n",
    "        # Storage for layer outputs\n",
    "        perception_outputs = []  # One per level\n",
    "        reference_outputs = []   # One per level\n",
    "        comparator_outputs = []  # One per level (these become Errors output)\n",
    "        output_layer_outputs = []  # One per level\n",
    "        \n",
    "        # TWO-PASS APPROACH: Build perception/output first, then reference layers\n",
    "        # This is necessary because reference inputs for lower levels come from\n",
    "        # output layers of higher levels that don't exist yet in a single pass\n",
    "        \n",
    "        # === PASS 1: Build perception, comparator, and output layers ===\n",
    "        # We'll create temporary references and rebuild them in pass 2\n",
    "        temp_reference_inputs = []\n",
    "        \n",
    "        for level_idx, num_units in enumerate(self.levels):\n",
    "            level_name = f\"{level_idx:02d}\"\n",
    "            \n",
    "            # === PERCEPTION LAYER ===\n",
    "            # T014: Create perception layers with correct inputs per level\n",
    "            if level_idx == self.obs_connection_level:\n",
    "                # This level connects directly to environment observations\n",
    "                perception_input = observations\n",
    "            elif level_idx == 0:\n",
    "                # Level 0: if not observation level, use observations\n",
    "                perception_input = observations\n",
    "            else:\n",
    "                # Higher levels: perceive output from level below\n",
    "                perception_input = output_layer_outputs[level_idx - 1]\n",
    "            \n",
    "            # Create perception layer (weighted sum with activation)\n",
    "            perception = layers.Dense(\n",
    "                units=num_units,\n",
    "                activation=self.activation_funcs[level_idx],\n",
    "                use_bias=True,\n",
    "                name=f'PL{level_name}',\n",
    "                kernel_initializer=self._get_weight_initializer(self.weight_types[level_idx])\n",
    "            )(perception_input)\n",
    "            perception_outputs.append(perception)\n",
    "            \n",
    "            # Store temp reference input for this level (will be properly connected in pass 2)\n",
    "            temp_reference_inputs.append(None)\n",
    "            reference_outputs.append(None)  # Placeholder\n",
    "            \n",
    "            # Create temporary comparator and output for structure\n",
    "            # These will be rebuilt in pass 2 with correct reference connections\n",
    "            comparator_outputs.append(None)  # Placeholder\n",
    "            \n",
    "            # Create output layer placeholder (just pass through comparator for now)\n",
    "            # Will be properly built in pass 2\n",
    "            output_layer_outputs.append(None)  # Placeholder\n",
    "        \n",
    "        # === PASS 2: Build reference, comparator, and output layers with correct connections ===\n",
    "        # Now we build from top to bottom so reference connections work\n",
    "        for level_idx in reversed(range(len(self.levels))):\n",
    "            num_units = self.levels[level_idx]\n",
    "            level_name = f\"{level_idx:02d}\"\n",
    "            \n",
    "            # === REFERENCE LAYER ===\n",
    "            # T015: Create reference layers with correct inputs per level\n",
    "            if level_idx == len(self.levels) - 1:\n",
    "                # Highest level: reference comes from external reference input\n",
    "                reference_input = references_input\n",
    "            else:\n",
    "                # Lower levels: reference comes from output of level above\n",
    "                # This now works because we're building top-down and higher levels exist\n",
    "                reference_input = output_layer_outputs[level_idx + 1]\n",
    "            \n",
    "            # Create reference layer (weighted sum with activation)\n",
    "            reference = layers.Dense(\n",
    "                units=num_units,\n",
    "                activation=self.activation_funcs[level_idx],\n",
    "                use_bias=True,\n",
    "                name=f'RL{level_name}',\n",
    "                kernel_initializer=self._get_weight_initializer(self.weight_types[level_idx])\n",
    "            )(reference_input)\n",
    "            reference_outputs[level_idx] = reference\n",
    "            \n",
    "            # === COMPARATOR LAYER ===\n",
    "            # Subtract perception from reference (error = reference - perception)\n",
    "            comparator = layers.Subtract(name=f'CL{level_name}')([reference, perception_outputs[level_idx]])\n",
    "            comparator_outputs[level_idx] = comparator\n",
    "            \n",
    "            # === OUTPUT LAYER ===\n",
    "            # Element-wise multiplication with learnable weights\n",
    "            # For now, we'll use a simpler approach: just pass through the comparator\n",
    "            # This will be enhanced in later tasks to support proper weighted outputs\n",
    "            output_layer_outputs[level_idx] = comparator\n",
    "        \n",
    "        # Connect actions to the output of level 0\n",
    "        # and errors to all comparator outputs\n",
    "        \n",
    "        # Actions output: from Level 0 output layer\n",
    "        if len(self.levels) == 1:\n",
    "            actions = output_layer_outputs[0]\n",
    "        else:\n",
    "            actions = output_layer_outputs[0]\n",
    "        \n",
    "        # For discrete action spaces, we need to ensure output matches action dimension\n",
    "        if action_dim != self.levels[0]:\n",
    "            # Add a final dense layer to map to action space\n",
    "            actions = layers.Dense(\n",
    "                units=action_dim,\n",
    "                activation='linear',\n",
    "                use_bias=True,\n",
    "                name='Actions_final'\n",
    "            )(actions)\n",
    "        else:\n",
    "            actions = layers.Activation('linear', name='Actions')(actions)\n",
    "        \n",
    "        # Errors output: concatenate all comparator outputs\n",
    "        if len(comparator_outputs) > 1:\n",
    "            errors = layers.Concatenate(name='Errors')(comparator_outputs)\n",
    "        else:\n",
    "            errors = layers.Activation('linear', name='Errors')(comparator_outputs[0])\n",
    "        \n",
    "        # Build the model\n",
    "        self.model = keras.Model(\n",
    "            inputs=[observations, references_input],\n",
    "            outputs=[actions, errors],\n",
    "            name='DHPCTIndividual'\n",
    "        )\n",
    "        \n",
    "        # Store initial weights\n",
    "        self._store_weights()\n",
    "        \n",
    "    def _get_weight_initializer(self, weight_type: str):\n",
    "        \"\"\"Get Keras weight initializer based on weight type.\"\"\"\n",
    "        if weight_type == \"float\":\n",
    "            return keras.initializers.GlorotUniform(seed=self.random_seed)\n",
    "        elif weight_type == \"boolean\":\n",
    "            # Boolean: initialize to 0 or 1\n",
    "            def boolean_init(shape, dtype=None):\n",
    "                return tf.cast(tf.random.uniform(shape, 0, 2, dtype=tf.int32, seed=self.random_seed), dtype=tf.float32)\n",
    "            return boolean_init\n",
    "        elif weight_type == \"ternary\":\n",
    "            # Ternary: initialize to -1, 0, or 1\n",
    "            def ternary_init(shape, dtype=None):\n",
    "                return tf.cast(tf.random.uniform(shape, -1, 2, dtype=tf.int32, seed=self.random_seed), dtype=tf.float32)\n",
    "            return ternary_init\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown weight_type: {weight_type}\")\n",
    "    \n",
    "    def _create_weight_layer(self, num_units: int, weight_type: str, name: str):\n",
    "        \"\"\"Create a constant weight layer for element-wise multiplication.\"\"\"\n",
    "        # Create trainable weights as a layer\n",
    "        initializer = self._get_weight_initializer(weight_type)\n",
    "        initial_weights = initializer((num_units,))\n",
    "        \n",
    "        # Use a Lambda layer to create constant weights (trainable via model)\n",
    "        # Actually, we should use a simple constant that can be updated\n",
    "        # For now, create a ones layer that will be weighted\n",
    "        weight_values = layers.Lambda(\n",
    "            lambda x: tf.ones_like(x) * initial_weights,\n",
    "            name=name\n",
    "        )\n",
    "        \n",
    "        # Better approach: use a trainable variable\n",
    "        # This is tricky in Functional API, so let's use a Dense layer with no bias\n",
    "        # and input of ones\n",
    "        return layers.Lambda(lambda x: x, name=name)  # Simplified for now\n",
    "    \n",
    "    def _store_weights(self):\n",
    "        \"\"\"Store current model weights in weights dictionary.\"\"\"\n",
    "        if self.model is None:\n",
    "            return\n",
    "        \n",
    "        for layer in self.model.layers:\n",
    "            if len(layer.get_weights()) > 0:\n",
    "                self.weights[layer.name] = [w.copy() for w in layer.get_weights()]\n",
    "    \n",
    "    def run(\n",
    "        self,\n",
    "        steps: int = 500,\n",
    "        train: bool = False,\n",
    "        early_termination: bool = True,\n",
    "        record_history: bool = False,\n",
    "        train_every_n_steps: int = 1,\n",
    "        learning_rate: float = 0.01,\n",
    "        optimizer: str = \"adam\",\n",
    "        error_weight_coefficients: Optional[List[float]] = None,\n",
    "        render: bool = False\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Execute individual in environment and return fitness.\n",
    "        \n",
    "        Args:\n",
    "            steps: Maximum number of environment steps\n",
    "            train: Enable online learning during execution\n",
    "            early_termination: Stop when environment returns done=True\n",
    "            record_history: Record ExecutionHistory\n",
    "            train_every_n_steps: Frequency of weight updates during training\n",
    "            learning_rate: Learning rate for online learning\n",
    "            optimizer: Optimizer name for training ('adam', 'sgd', etc.)\n",
    "            error_weight_coefficients: Weights for different level errors in training\n",
    "            render: Render environment during execution\n",
    "            \n",
    "        Returns:\n",
    "            Fitness score (typically cumulative reward)\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: If not compiled\n",
    "            EnvironmentError: If environment interaction fails\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Individual must be compiled before running\")\n",
    "        \n",
    "        # TODO: Implement environment execution (T021)\n",
    "        pass\n",
    "    \n",
    "    def config(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Return complete configuration dictionary.\n",
    "        \n",
    "        Returns:\n",
    "            Configuration dictionary with all hierarchy parameters and weights\n",
    "        \"\"\"\n",
    "        # TODO: Implement config serialization (T031)\n",
    "        pass\n",
    "    \n",
    "    def save_config(self, filepath: str):\n",
    "        \"\"\"\n",
    "        Save configuration to JSON file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to save configuration file\n",
    "        \"\"\"\n",
    "        # TODO: Implement config saving (T032)\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config: Dict[str, Any]) -> 'DHPCTIndividual':\n",
    "        \"\"\"\n",
    "        Create individual from configuration dictionary.\n",
    "        \n",
    "        Args:\n",
    "            config: HierarchyConfiguration dictionary\n",
    "            \n",
    "        Returns:\n",
    "            New compiled DHPCTIndividual with weights loaded\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If configuration is invalid\n",
    "            KeyError: If required keys missing from config\n",
    "        \"\"\"\n",
    "        # TODO: Implement from_config (T034)\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def load_config(cls, filepath: str) -> 'DHPCTIndividual':\n",
    "        \"\"\"\n",
    "        Load individual from JSON configuration file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to configuration file\n",
    "            \n",
    "        Returns:\n",
    "            New compiled DHPCTIndividual\n",
    "        \"\"\"\n",
    "        # TODO: Implement load_config (T033)\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def from_legacy_config(cls, legacy_config: Dict[str, Any]) -> 'DHPCTIndividual':\n",
    "        \"\"\"\n",
    "        Create individual from legacy configuration format.\n",
    "        \n",
    "        Args:\n",
    "            legacy_config: Configuration in legacy format\n",
    "            \n",
    "        Returns:\n",
    "            New DHPCTIndividual instance\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If legacy config cannot be converted\n",
    "        \"\"\"\n",
    "        # TODO: Implement from_legacy_config (T037)\n",
    "        pass\n",
    "    \n",
    "    def to_legacy_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Convert to legacy configuration format for backward compatibility.\n",
    "        \n",
    "        Returns:\n",
    "            Configuration dictionary in legacy format\n",
    "        \"\"\"\n",
    "        # TODO: Implement to_legacy_config (T036)\n",
    "        pass\n",
    "    \n",
    "    def mate(self, other: 'DHPCTIndividual') -> tuple['DHPCTIndividual', 'DHPCTIndividual']:\n",
    "        \"\"\"\n",
    "        Perform crossover with another individual to create offspring.\n",
    "        \n",
    "        Args:\n",
    "            other: Another DHPCTIndividual for mating\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of two offspring individuals\n",
    "        \"\"\"\n",
    "        # TODO: Implement mate operation (T071-T074)\n",
    "        pass\n",
    "    \n",
    "    def mutate(\n",
    "        self,\n",
    "        weight_prob: float = 0.1,\n",
    "        struct_prob: float = 0.05\n",
    "    ) -> 'DHPCTIndividual':\n",
    "        \"\"\"\n",
    "        Mutate weights and optionally structure.\n",
    "        \n",
    "        Args:\n",
    "            weight_prob: Probability of mutating each weight\n",
    "            struct_prob: Probability of structural mutations (add/remove levels/units)\n",
    "            \n",
    "        Returns:\n",
    "            Self (mutated in place)\n",
    "        \"\"\"\n",
    "        # TODO: Implement mutate operation (T075-T080)\n",
    "        pass\n",
    "    \n",
    "    def evaluate(\n",
    "        self,\n",
    "        nevals: int = 1,\n",
    "        aggregation: str = 'mean'\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate fitness over multiple runs.\n",
    "        \n",
    "        Args:\n",
    "            nevals: Number of evaluation runs\n",
    "            aggregation: How to aggregate results ('mean', 'max', 'min', 'median')\n",
    "            \n",
    "        Returns:\n",
    "            Aggregated fitness score\n",
    "        \"\"\"\n",
    "        # TODO: Implement evaluate with multiple runs (T081-T082)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea09e4",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a04f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
