# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_individual.ipynb.

# %% auto 0
__all__ = ['DHPCTDebugHelper', 'DHPCTIndividual']

# %% ../nbs/02_individual.ipynb 4
import gymnasium as gym
import tensorflow as tf
import numpy as np
import json


# %% ../nbs/02_individual.ipynb 5
class DHPCTDebugHelper:
    """
    Helper class for debugging DHPCTIndividual Keras models layer-by-layer.
    Uses a debug model that outputs all intermediate layer outputs.
    """
    def __init__(self, model, debug_model, layer_names):
        self.model = model
        self.debug_model = debug_model
        self.layer_names = layer_names

    @staticmethod
    def get_layer_name(layer):
        return layer.name

    @staticmethod
    def get_layer_weights(layer):
        return layer.get_weights() if hasattr(layer, 'get_weights') else None

    def report_values(self, all_outputs):
        """
        Print output values for each layer for a single step.
        """
        print("\nLayer-by-layer values:")
        for name, out in zip(self.layer_names, all_outputs):
            print(f"Layer {name}:")
            layer = self.model.get_layer(name)
            weights = self.get_layer_weights(layer)
            if weights is not None and len(weights) > 0:
                print(f"  Weights: {weights}")
            
            if isinstance(out, np.ndarray):
                print(f"  Output: {out}")
            elif hasattr(out, 'numpy'):
                print(f"  Output: {out.numpy()}")
            else:
                print(f"  Output: {out}")


# %% ../nbs/02_individual.ipynb 6
class DHPCTIndividual:
    """
    Represents an individual with a hierarchical PCT control system and an environment.
    """
    def __init__(self, env_name, env_props=None, levels=None, activation_funcs=None, weight_types=None, input_references=None, debug=False):
        self.env_name = env_name
        self.env_props = env_props or {}
        self.levels = levels or []
        self.activation_funcs = activation_funcs or {}
        self.weight_types = weight_types or {}
        self.input_references = input_references
        self.env = None
        self.model = None
        self.weights = {}
        self.debug = debug
        self._debug_helper = None
        self._debug_model = None
        self._debug_layer_names = None

    @classmethod
    def from_config(cls, config_dict):
        env_cfg = config_dict.get('env', {})
        hier_cfg = config_dict.get('hierarchy', {})
        weights = config_dict.get('weights', {})
        obj = cls(
            env_name=env_cfg.get('env_name'),
            env_props=env_cfg.get('properties'),
            levels=hier_cfg.get('levels'),
            activation_funcs=hier_cfg.get('activation_funcs'),
            weight_types=hier_cfg.get('weight_types'),
        )
        obj.weights = weights
        return obj

    def compile(self):
        """
        Build the environment and Keras model according to the DPCT hierarchical PCT specification and naming conventions.
        If debug is True, also build a debug model that outputs all intermediate layer outputs.
        """
        if not self.levels or not isinstance(self.levels, list) or not all(isinstance(l, int) and l > 0 for l in self.levels):
            raise ValueError("'levels' must be a non-empty list of positive integers. Got: {}".format(self.levels))
        self.env = gym.make(self.env_name, **self.env_props) if self.env_props else gym.make(self.env_name)
        # Observation and action space sizes
        space = self.env.observation_space
        shape = getattr(space, 'shape', None)
        if shape is not None and len(shape) > 0:
            obs_space = shape[0]
        elif isinstance(space, gym.spaces.Discrete):
            obs_space = 1
        else:
            raise ValueError("Unsupported observation space type")
        action_space = self.env.action_space
        act_shape = getattr(action_space, 'shape', None)
        if act_shape is not None and len(act_shape) > 0:
            act_space = act_shape[0]
        elif isinstance(action_space, gym.spaces.Discrete):
            act_space = 1
        else:
            act_space = 1
        # Naming conventions
        def lname(prefix, level):
            return f"{prefix}L{level:02d}"
        # Input layers
        obs_input = tf.keras.Input(shape=(obs_space,), name='Observations')
        ref_shape = (len(self.input_references),) if self.input_references is not None else (self.levels[-1],)
        ref_input = tf.keras.Input(shape=ref_shape, name='Reference')
        # --- First: Perception layers ---
        perceptions = []
        act0 = self.activation_funcs.get(0, 'linear')
        p0 = tf.keras.layers.Dense(self.levels[0], use_bias=False, activation=act0, name=lname('P', 0))(obs_input)
        perceptions.append(p0)
        for i in range(1, len(self.levels)):
            act = self.activation_funcs.get(i, 'linear')
            p = tf.keras.layers.Dense(self.levels[i], use_bias=False, activation=act, name=lname('P', i))(perceptions[i-1])
            perceptions.append(p)
        # --- Second: Reference, Comparator, Output layers ---
        references = [None] * len(self.levels)
        comparators = [None] * len(self.levels)
        outputs = [None] * len(self.levels)
        # Top level reference from ref_input
        top = len(self.levels) - 1
        references[top] = tf.keras.layers.Lambda(lambda x: x, name=lname('R', top))(ref_input)
        # Loop from top level downwards
        for i in reversed(range(len(self.levels))):
            if i != top:
                # Reference: weighted sum of output from above
                references[i] = tf.keras.layers.Dense(self.levels[i], use_bias=False, activation='linear', name=lname('R', i))(outputs[i+1])
            # Comparator: reference - perception
            comparators[i] = tf.keras.layers.Subtract(name=lname('C', i))([references[i], perceptions[i]])
            # Output: element-wise multiplication of weights and comparator
            outputs[i] = tf.keras.layers.Multiply(name=lname('O', i))([comparators[i], tf.keras.layers.Dense(self.levels[i], use_bias=False, activation='linear')(comparators[i])])
        # --- Third: Actions and Errors layers ---
        actions = tf.keras.layers.Dense(act_space, use_bias=False, activation='linear', name='Actions')(outputs[0])
        errors = tf.keras.layers.Concatenate(name='Errors')(comparators) if len(comparators) > 1 else comparators[0]
        self.model = tf.keras.Model(inputs=[obs_input, ref_input], outputs=[actions, errors])
        # If debug, create a debug model with all layer outputs
        if self.debug:
            debug_layers = [layer for layer in self.model.layers if 'input' not in layer.name.lower() and layer.name not in ['Observations', 'Reference']]
            debug_layer_outputs = [layer.output for layer in debug_layers]
            debug_layer_names = [layer.name for layer in debug_layers]
            self._debug_model = tf.keras.Model(inputs=[obs_input, ref_input], outputs=debug_layer_outputs)
            self._debug_layer_names = debug_layer_names
            self._debug_helper = DHPCTDebugHelper(self.model, self._debug_model, self._debug_layer_names)

    def config(self):
        return {
            'env': {
                'env_name': self.env_name,
                'properties': self.env_props
            },
            'hierarchy': {
                'levels': self.levels,
                'activation_funcs': self.activation_funcs,
                'weight_types': self.weight_types
            },
            'weights': self.weights
        }

    def save_config(self, filepath):
        try:
            with open(filepath, 'w') as f:
                json.dump(self.config(), f, indent=2)
            return True
        except Exception:
            return False

    def debug_step(self, step, obs_input, ref_input, action):
        print(f"\n--- Step {step+1} ---")
        print(f"Observation: {obs_input}")
        print(f"Reference input: {ref_input}")

        if self.debug and self._debug_helper is not None:
            all_outputs = self._debug_model.predict([obs_input, ref_input])
            if not isinstance(all_outputs, list):
                all_outputs = [all_outputs]
            self._debug_helper.report_values(all_outputs)
        print(f"Action chosen: {action}")


    def run(self, steps, train=False, early_termination=False):
        """
        Run the individual in its environment
        Parameters:
        - steps: Number of timesteps to run
        - train: Whether to enable online learning during execution
        - early_termination: Whether to terminate early based on environment signals
        - debug: If True, print weights, input values, and output values for each layer at each step
        """
        if not self.levels or len(self.levels) == 0:
            raise ValueError("Hierarchy levels are not defined. Please provide a non-empty levels list.")
        if self.env is None or self.model is None:
            self.compile()
        if self.env is None:
            raise RuntimeError("Environment is not initialized. Call compile() first.")
        if self.model is None:
            raise RuntimeError("Model is not initialized. There was an error during compile().")
        obs = self.env.reset()
        if isinstance(obs, tuple):
            obs = obs[0]
        total_reward = 0
        for step in range(steps):
            obs_input = np.expand_dims(obs, axis=0)
            ref_input = np.zeros((1, self.levels[-1])) if self.levels else np.zeros((1, 1))
            model_inputs = [obs_input, ref_input]
            model_outputs = self.model(model_inputs)
            print(f"Model outputs: {model_outputs}")
            actions = model_outputs[0].numpy().squeeze()
            if hasattr(self.env.action_space, 'n'):
                action = int(np.argmax(actions))
            else:
                action = actions
            if self.debug:
                self.debug_step(step, obs_input, ref_input, action)
            step_result = self.env.step(action)
            if len(step_result) == 5:
                obs, reward, terminated, truncated, _ = step_result
            else:
                obs, reward, done, _ = step_result
                terminated = done
                truncated = False
            total_reward += reward
            if early_termination and (terminated or truncated):
                break
        self.env.close()
        return total_reward

    def mate(self, other):
        """
        Create two new individuals by crossing this one with another.
        Structure is crossed over (one-point crossover), weights are blended.
        Returns:
            tuple: (child1, child2) as new DHPCTIndividual instances
        """
        import copy
        import random
        # Crossover for levels (structure): one-point crossover
        if not self.levels or not other.levels or len(self.levels) != len(other.levels):
            # fallback: just copy
            return copy.deepcopy(self), copy.deepcopy(other)
        point = random.randint(1, len(self.levels)-1)
        child1_levels = self.levels[:point] + other.levels[point:]
        child2_levels = other.levels[:point] + self.levels[point:]
        # Crossover for activation_funcs and weight_types (shallow merge)
        child1_af = {**self.activation_funcs, **{k: other.activation_funcs.get(k, v) for k, v in self.activation_funcs.items()}}
        child2_af = {**other.activation_funcs, **{k: self.activation_funcs.get(k, v) for k, v in other.activation_funcs.items()}}
        child1_wt = {**self.weight_types, **{k: other.weight_types.get(k, v) for k, v in self.weight_types.items()}}
        child2_wt = {**other.weight_types, **{k: self.weight_types.get(k, v) for k, v in other.weight_types.items()}}
        # Blend weights if present (simple average for matching keys)
        def blend_weights(w1, w2):
            if not w1 or not w2:
                return w1 or w2 or {}
            blended = {}
            for k in set(w1.keys()).union(w2.keys()):
                v1 = w1.get(k)
                v2 = w2.get(k)
                if isinstance(v1, (int, float)) and isinstance(v2, (int, float)):
                    blended[k] = (v1 + v2) / 2
                elif isinstance(v1, dict) and isinstance(v2, dict):
                    blended[k] = blend_weights(v1, v2)
                else:
                    blended[k] = v1 if v1 is not None else v2
            return blended
        child1_weights = blend_weights(self.weights, other.weights)
        child2_weights = blend_weights(other.weights, self.weights)
        # Create children
        child1 = DHPCTIndividual(
            env_name=self.env_name,
            env_props=copy.deepcopy(self.env_props),
            levels=child1_levels,
            activation_funcs=child1_af,
            weight_types=child1_wt
        )
        child2 = DHPCTIndividual(
            env_name=other.env_name,
            env_props=copy.deepcopy(other.env_props),
            levels=child2_levels,
            activation_funcs=child2_af,
            weight_types=child2_wt
        )
        child1.weights = child1_weights
        child2.weights = child2_weights
        return child1, child2

    def mutate(self, struct_prob=0.1, weight_prob=0.1):
        # Placeholder: no-op
        pass

    def evaluate(self, nevals=1):
        # Placeholder: average reward over nevals runs
        scores = [self.run(steps=200) for _ in range(nevals)]
        return np.mean(scores)

